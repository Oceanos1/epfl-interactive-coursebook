{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from helpers import read_raw, write_processed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/pickle/dep.pickle')\n",
    "courseindex = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prereq_for = df.prerequisite_for.apply(lambda x: \" \".join(list(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(\"([A-Za-z]{2,6}[-\\s]*\\d{3}(?:\\s*\\([A-Za-z0-9]+\\))?)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prereq_matches = prereq_for.apply(lambda x: regex.findall(x))\n",
    "prereq = prereq_matches[prereq_matches.apply(lambda x: len(x) > 0)]\n",
    "prereq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required = df.required.apply(lambda x: \" \".join(list(x)))\n",
    "\n",
    "req_matches = required.apply(lambda x: regex.findall(x))\n",
    "req = req_matches[req_matches.apply(lambda x: len(x) > 0)]\n",
    "req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended = df.recommended.apply(lambda x: \" \".join(list(x)))\n",
    "\n",
    "rec_matches = recommended.apply(lambda x: regex.findall(x))\n",
    "rec_matches[rec_matches.apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idea : concat together required and prereq_for\n",
    "#first, inverse the required into prerequisite\n",
    "inv_req = {}\n",
    "for k, v in req.items():\n",
    "    for e in v:\n",
    "        _e = e.upper()\n",
    "        inv_req[_e] = inv_req.get(_e, [])\n",
    "        inv_req[_e].append(k.upper())\n",
    "\n",
    "        \n",
    "print(len(inv_req))\n",
    "inv_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in prereq.items():\n",
    "    _k = k.upper()\n",
    "    inv_req[_k] = inv_req.get(_k,[])\n",
    "    for elem in v:\n",
    "        inv_req[_k].append(elem.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged version\n",
    "print(len(inv_req))\n",
    "inv_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in inv_req.items():\n",
    "     inv_req[key] = list(set(inv_req[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(inv_req))\n",
    "inv_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_processed_dict('epfl_prereq',inv_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/pickle/dep.pickle')\n",
    "courseindex = df.index\n",
    "print(courseindex[:20])\n",
    "uppercourseindex = df.index.map(lambda x: x.upper())\n",
    "print(uppercourseindex[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_name(code):\n",
    "    #uppercase\n",
    "    upper = code.upper()\n",
    "    #leave the codes that don't correspond to a course alone\n",
    "    if not any(char.isdigit() for char in upper):\n",
    "        return upper\n",
    "    upper = upper.replace(\"-\", \"\").replace(\" \", \"\")\n",
    "    #split when encountering first digit\n",
    "    first_digit = re.search('\\d', upper).group(0)\n",
    "    index = upper.find(first_digit)\n",
    "    res_left = upper[:index]\n",
    "    res_right = upper[index:]\n",
    "    res = res_left + '-' + res_right\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_df(x):\n",
    "    res = pd.DataFrame.from_dict(x, orient='index')\n",
    "    res['prerequisite_for'] = res.apply(list, axis=1)\n",
    "    res = res['prerequisite_for'].map(lambda x: list(filter(lambda a: a!= None, x))).reset_index().rename(columns={'index':'course_code'})\n",
    "    res['course_code'] = res['course_code'].map(fix_name)\n",
    "    res['prerequisite_for'] = res['prerequisite_for'].map(lambda x: list(map(fix_name, x)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_name(code):\n",
    "    if 'MASTER' in code or 'MINOR' in code or 'PROJECT' in code or 'LAB' in code:\n",
    "        return code\n",
    "    res = code.upper()\n",
    "    #match case\n",
    "    modifier = \"\"\n",
    "    if res.find(\"(\") != -1:\n",
    "        modifier = re.search('\\([A-Za-z0-9]{1,2}\\)', res).group(0)\n",
    "    if res in uppercourseindex:\n",
    "        return courseindex[uppercourseindex.get_loc(res)]\n",
    "    elif len(modifier)>0 and res[:-len(modifier)] in uppercourseindex:\n",
    "        return courseindex[uppercourseindex.get_loc(res[:-len(modifier)])]\n",
    "    elif res + \"(a)\" in uppercourseindex:\n",
    "        return courseindex[uppercourseindex.get_loc(res_new.upper())]\n",
    "    else:\n",
    "        return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/merged_prerequisites.json') as file:\n",
    "        merged = json.load(file)\n",
    "merged = dict_to_df(merged).set_index('course_code')\n",
    "merged = merged.sort_index()\n",
    "merged = merged.groupby(['course_code'])['prerequisite_for'].apply(lambda x: sorted(list(set(sum(x, [])))))\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [\n",
    "    { \"source\": source, \"target\": target }\n",
    "    for (source, targets) in merged.items()\n",
    "    for target in targets\n",
    "]\n",
    "\n",
    "links_df = pd.DataFrame.from_dict(links)\n",
    "links_df['source'] = links_df['source'].apply(patch_name)\n",
    "links_df['target'] = links_df['target'].apply(patch_name)\n",
    "links_df = links_df[(links_df.source.isin(df.index) & links_df.target.isin(df.index))]\n",
    "links_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_dict = links_df.to_json(path_or_buf='../data/links3004.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(f'../data/links.json', 'w') as json_file:\n",
    "#        json.dump(links, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inv_df = dict_to_df(inv_req)\n",
    "#inv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(f'../data/epfl_prereq_byhand.json') as file:\n",
    "#        by_hand = json.load(file)\n",
    "#by_hand = dict_to_df(by_hand)\n",
    "#by_hand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inv_df['course_code'].size)\n",
    "print(by_hand['course_code'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df1, df2):\n",
    "    merged = df1.merge(df2, on='course_code', how='outer')\n",
    "    merged = merged.apply(lambda x: x.apply(lambda x: [] if x is np.nan else x))\n",
    "    merged['prerequisite_for'] = merged['prerequisite_for_x'] + merged['prerequisite_for_y']\n",
    "    merged = merged[['course_code','prerequisite_for']]\n",
    "    merged['prerequisite_for'] = merged['prerequisite_for'].apply(lambda x: sorted(list(set(x))))\n",
    "    return merged.set_index('course_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merge(inv_df, by_hand)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_method():\n",
    "    wrong_codes = ['com 480(a)', 'COM  480(a)', 'com480 (A)', '  com-480  (A)', 'COM-480(a)']\n",
    "    good_code = 'COM-480(A)'\n",
    "    for wrong_code in wrong_codes:\n",
    "        fixed = fix_name(wrong_code)\n",
    "        if fixed != good_code:\n",
    "            print(\"%s != %s\"% (fixed, good_code))\n",
    "            return False\n",
    "    return True\n",
    "test_method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.sort_index()\n",
    "merged = merged.groupby(['course_code'])['prerequisite_for'].apply(lambda x: sorted(list(set(sum(x, [])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_json(path_or_buf='../data/merged_prerequisites2.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/merged_prerequisites.json\") as file:\n",
    "    merged = json.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# courseindex\n",
    "\n",
    "links = [\n",
    "    { \"source\": source, \"target\": target }\n",
    "    for (source, targets) in merged.items()\n",
    "    for target in targets\n",
    "]\n",
    "\n",
    "links_df = pd.DataFrame.from_dict(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df = links_df[(~links_df.source.isin(courseindex) | ~links_df.target.isin(courseindex))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df.to_json(path_or_buf='../data/processed/links.json', orient=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = read_raw('master', 'processed')\n",
    "links = read_raw('links', 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master[\"links\"] = list(links.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_processed_dict(\"master\", master)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
